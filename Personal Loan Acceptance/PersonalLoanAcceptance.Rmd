---
title: "Group15HW4"
author: "YIWEI LI, TUSHAR RAO"
date: "11/22/2020"
output: pdf_document
---

```{r}
#problem 1
#AConsider the following customer: Age=40, Experience=10, Income=84, Family=2, CCAvg=2, Education2=1, Education3=0, Mortgage=O, Securities Account=O, CD Account=O, Online=1 and Credit.card = 1. Perform a k-NN classification with all predictors except ID and ZIP code using k = 1. Remember to transform categorical predictors with more than two categories into dummy variables first. Specify the success class as 1 (loan acceptance), and use the default cutoff value of 0.5. How would this customer be classified?
library(readxl)
library(caret)
library(lattice)
library(class)
UB<-read_excel("UniversalBank.xlsx",sheet="Data")
#According to the question, we need to add two columns education2 and education 3 also we need to make the education2=1, education3=0 
UB$Education1<-- (ifelse(UB[,8]==1,1,0))
UB$Education2 <- (ifelse(UB[,8]==2,1,0))
UB$Education3 <- (ifelse(UB[,8]==3,1,0))
#According to the requirment the first step is to partition the data into trainning data and Validation data 
trainingUB<- sample(row.names(UB), 0.6*dim(UB)[1])
ValidationUB<- setdiff(row.names(UB), trainingUB)
training.df <- UB[trainingUB,]
validation.df <- UB[ValidationUB,]

#View(UB)
#we also need to remove the columns we do not need 

training.new.df <- training.df[,-which(names(training.df) %in% c("ID","ZIP Code","Education"))]
validation.new.df <- validation.df[,-which(names(validation.df) %in% c("ID","ZIP Code","Education"))]

TS.df <- data.frame('Age'=40, 'Experience'=10, 'Income'=84, 'Family'=2, 
                           'CCAvg'=2,'Mortgage'=0, 'Education1'=0, 'Education2'=1, 
                           'Education3'=0,'Securities.Account'=0, 'CD.Account'=0,
                           'Online'=1,'CreditCard'= 1)

TS.norm <- TS.df
norm <- preProcess(training.new.df[,c(-7:-13)],method = c("center", "scale"))
TS.norm[,c(1:6)] <- predict(norm, TS.norm[,c(1:6)])
TS.norm
UB$`Personal Loan`<-factor(UB$`Personal Loan`)
Knn.test<-knn(train=training.new.df[,-7],test=TS.norm,cl=training.new.df$`Personal Loan`,k=1)
Knn.test

```
#Answer for Question 1 
#according to the resulut of KNN Test we got the asnwer is o at the levwl 0 and 1 which means the loando not accept


#Question b
#What is a choice of k that balances between overfitting and ignoring the predictor information?
```{r}
library(caret)
library(class)
library(lattice)
library(readxl)

UB<-read_excel("UniversalBank.xlsx",sheet="Data")
trainingUB<- sample(row.names(UB), 0.6*dim(UB)[1])
ValidationUB<- setdiff(row.names(UB), trainingUB)
training.df <- UB[trainingUB,]
validation.df <- UB[ValidationUB,]
training.new.df <- training.df[,-which(names(training.df) %in% c("ID","ZIP Code","Education"))]
validation.new.df <- validation.df[,-which(names(validation.df) %in% c("ID","ZIP Code","Education"))]
set.seed(5)
accuracy.a <- data.frame(k=seq(1,10,1),accuracy=rep(0,10))
for(i in c(1:10)){
   knn.pred<-knn(training.new.df[,-7],validation.new.df[,-7],
                 cl=training.new.df$`Personal Loan`,k = i)
                 accuracy.a[i,2]<-confusionMatrix(knn.pred,factor(validation.new.df$`Personal Loan`))$overall[1]
}

accuracy.a
plot(accuracy.a, type = "b")


 
```
#Question c Show the classification matrix for the validation data that results from using the best k. 
#We are going to use k values 3 according to the last question's answer.
```{r}
pred_knn<-knn(training.new.df[,-7],validation.new.df[,-7],
                 cl=training.new.df$`Personal Loan`,k = 3)
pred_knn
confusionMatrix(pred_knn,factor(validation.new.df$`Personal Loan`))
```
#Question d Consider the following customer: Age=40, Experience=10, Income=84, Family=2, CCAvg=2, Education 1=0, Education 2=1, Education 3=0, Mortgage=0, Securities Account=0, CD Account=0, Online=1 and Credit Card=1. Classify the customer using the best k.
#We are going to use k values 3 according to the 2nd question's answer.
```{r}
knn_test<-knn(train=training.new.df[,-7],test = validation.new.df[,-7],cl=training.new.df$`Personal Loan`, k=3)
knn_test
```
#e. Repartition the data, this time into training, validation, and test sets (50% : 30% : 20%). Apply the k-NN method with the k chosen above. Compare the classification matrix of the test set with that of the training and validation sets. Comment on the differences and their reason
#  Subset the data into traing,validation and test sets
```{r}
index_train <- sample(row.names(UB), 0.5*dim(UB)[1])
index_valid<- sample(row.names(UB), 0.3*dim(UB)[1])
index_test<- sample(row.names(UB), 0.2*dim(UB)[1])
df_train <- UB[index_train,]
df_valid<- UB[index_valid,]
df_test<- UB[index_test,]
```
# Remove variables 
```{r}
train_e<-df_train[,-which(names(df_train) %in% c("ID","ZIP Code","Education"))]
valid_e<-df_valid[,-which(names(df_valid) %in% c("ID","ZIP Code","Education"))]
test_e<-df_test[,-which(names(df_test) %in% c("ID","ZIP Code","Education"))]
```
# data normalization
```{r}
train_E<-train_e
valid_E<-valid_e
test_E<-test_e
train_E[1:6]<-as.data.frame(lapply(train_e[1:6],normalize))
valid_E[1:6]<-as.data.frame(lapply(valid_e[1:6],normalize))
test_E[1:6] <- as.data.frame(lapply(test_e[1:6],normalize))
```
#perform knn model
```{r}
knn_train <- knn(train_E[,-7],train_E[,-7],cl=train_E$`Personal Loan`,k = 3) 
knn_valid <- knn(train_E[,-7],valid_E[,-7],cl=train_E$`Personal Loan`,k = 3) 
knn_test <- knn(train_E[,-7],test_E[,-7],cl=train_E$`Personal Loan`,k = 3) 
head(knn_train)
head(knn_valid)
head(knn_test)

acc_e <- data.frame(subset=c('Train','Valid','Test'),accuracy=rep(0,3))
acc_e[1,2] <- confusionMatrix(knn_train,factor(train_E$`Personal Loan`))$overall[1]
acc_e[2,2] <- confusionMatrix(knn_valid,factor(train_E$`Personal Loan`))$overall[1]
acc_e[3,2] <- confusionMatrix(knn_test,factor(train_E$`Personal Loan`))$overall[1]
acc_e
```
#Answer for question E 
#according to the problem B we know that the when k=3 is the best vale to choose the dateset.it is relly clear that the accureat is equal to 0.903 which is really high and we got the similiar accurate between validate data and test data 

#Question 2 
#A
```{r}
BH.df<-read_excel("BostonHousing.xlsx",sheet = "Data")
View(BH.df)
library(readxl)
library(class)
library(caret)
#select the variables
bha <- BH.df[1:13]
bha$MEDV<-factor(BH.df$MEDV)
#Partition the data into training (60%) and validation (40%) sets.
TRAIN <- sample(rownames(bha),dim(bha)[1]*0.6)
train <- bha [TRAIN,]
TEST <- setdiff(rownames(bha),TRAIN)
test <- bha[TEST,]
N2 <- preProcess(train[,c(1:3)],method = c("center", "scale")) 
train_n <- train
test_n <- test
train_n[,c(-4,-13)] <- predict(N2, train[,c(1:3)]) 
test_n[,c(-4,-13)] <- predict(N2, test[,c(1:3)])
head(train_n)
```

```{r}
#a.Perform a k-NN prediction with all 13 predictors (ignore the CAT.MEDV column),trying values of k from 1 to 5. Make sure to normalize the data (click "normalize input data"). What is the best k chosen? What does it mean?
library(class)
library(e1071)
library(gmodels)
library(kknn)
library(Metrics)

set.seed(1000)
acc.df <- data.frame(k=seq(1,5,1),RMSE=rep(0,5))
for (i in 1:5){
pred_knn <- knn(train_n[,-13],test_n[,-13],cl=train_n$MEDV,k=i)
acc.df[i,2] <- rmse(as.numeric(test$MEDV),as.numeric(pred_knn)) 
}
acc.df
```
#Answer for question a: When RMSE is the lowest, the k value is 1 so 1 is the best k value.
```{r}
#b. Predict the MEDV for a tract with the following information, using the best k:
test<- data.frame('CRIM'=0.2,'ZN'=0,'INDUS'=7,'CHAS'=0,'NOX'=0.538,'RM'=6,'AGE'=62,'DIS'=4.7,'RAD'=4, 'TAX'=307,'PTRATIO'=21,'LSTAT'=10)
test_n<- test
test_n[,-4] <- predict(N2, test[,-4])
test_n
test_knn <- knn(train_n[,-13],test,cl=train_n$MEDV,k=1) 
test_knn
```
#CWhy is the error of the training data zero?
#answer for question c: becasue in the model we design it automatic choose and must be one hundrend percent right when k=1 therefore it is zero error in the training data 

#DWhy is the validation data error overly optimistic compared to the error rate when applying this k-NN predictor to new data?
#The answer for this question is that validation data is come form the and also is the sample of the new data. while when we use the knn method to predict the variable the overly optimistic is not evitbale therefore the error is overly optimistic 

#EIf the purpose is to predict MEDV for several thousands of new tracts, what would be the disadvantage of using k-NN prediction? List the operations that the algorithm goes through in order to produce each prediction.
#answer for question E 
#A the kNN method is not suitb for predictor a large number of tracts and the calculate will be too large and complicate 
#B the first step is we need to normalization the dataset 
### the second step is we need the find the suitable value of k 
### the third step is we need to find the distance between our dataset and training dataset 
### The fourth step is we need to arrgane the value of distacne in order therewe can sorted 


```{r}
#Problem 3

library(readxl)
Acc <- read_excel("Accidents.xlsx", sheet = "Data")

Acc$Injury <- as.factor(ifelse(Acc$MAX_SEV_IR < 1, "NO", "YES"))
Acc1 <- Acc[,-24]

index <- sample(1:nrow(Acc), size=0.5*nrow(Acc))
test <- Acc[index,]
train<- Acc[-index,]

library(e1071)
levels(train$Injury)
model1 <- naiveBayes(Injury~., data = train)
class(model1) 
p <- predict(model1,test)
table(p)

library(e1071)
Acc2 <-Acc1[1:12,c("Injury", "WEATHER_R", "TRAF_CON_R")]
Acc2
table(Acc2$WEATHER_R, Acc2$TRAF_CON_R, Acc2$Injury)

Acc2$Injury <- ifelse(Acc2$Injury == "YES", 1, 0)
Acc2$Injury <- as.factor(Acc2$Injury)

model2 <- naiveBayes(Injury ~ WEATHER_R + TRAF_CON_R, data = Acc2)
class(model2)

model3 <- predict(model2, Acc2)
table(model3)

Acc1$Injury<-ifelse(Acc1$Injury == "YES", 1, 0)
Acc1$Injury<-as.factor(Acc1$Injury)
train1<-Acc1[1:25310, ]
valid1<-Acc1[25311:42183, ]

model4 <- naiveBayes(Injury ~ HOUR_I_R + ALCHL_I + WKDY_I_R + LGTCON_I_R + MANCOL_I_R + SPD_LIM + VEH_INVL, data=train1)
model4

p2 <- predict(model4, valid1)
table(p2, valid1$Injury)
```
A) From p2, we can see the probability of Yes is 50.87, and that of No is 49.12.

B)

```{r}
Ac.df <- read_excel("Accidents.xlsx", sheet = "Data")
Ac.df$INJURY <- ifelse(Ac.df$MAX_SEV_IR>0, "Yes", "No")
Ac.df
x.df <- Ac.df[1:12,c("INJURY","WEATHER_R","TRAF_CON_R")]
x.df
```




i)Pivot Table

```{r}
knitr::include_graphics('PT.PNG')
```
ii) Exact Bayes calculation for INJURY=Yes

```{r}
#P(Injury=yes|WEATHER_R = 1, TRAF_CON_R =0):
n1 <- 2/3 * 3/12
d1 <- 3/12
prob1 <- n1/d1

#P(Injury=yes|WEATHER_R = 1, TRAF_CON_R =1):
n2 <- 0 * 3/12
d2 <- 1/12
prob2 <- n2/d2

#P(Injury=yes| WEATHER_R = 1, TRAF_CON_R =2):
n3 <- 0 * 3/12
d3 <- 1/12
prob3 <- n3/d3

#P(Injury=yes| WEATHER_R = 2, TRAF_CON_R =0):
n4 <- 1/3 * 3/12
d4 <- 6/12
prob4 <- n4/d4

#P(Injury=yes| WEATHER_R = 2, TRAF_CON_R =1):
n5 <- 0 * 3/12
d5 <- 1/12
prob5 <- n5/d5

#P(Injury=yes| WEATHER_R = 2, TRAF_CON_R =2):
n6 <- 0 * 3/12
d6 <- 0
prob6 <- n6/d6

x<-c(1,2,3,4,5,6)
y<-c(prob1,prob2,prob3,prob4,prob5,prob6)
prob.df<-data.frame(x,y)
names(prob.df)<-c('#','Probability')
prob.df
```


(iii)Classification of accidents with cutoff=0.5:
```{r}
acc1.prob<-x.df
head(acc1.prob)

prob.injury <- c(0.667, 0.167, 0, 0, 0.667, 0.167, 0.167, 0.667, 0.167, 0.167, 0.167, 0)
#acc1.prob['PROB_INJURY'] <- NA
acc1.prob$PROB_INJURY<-prob.injury


acc1.prob$PREDICT_PROB<-ifelse(acc1.prob$PROB_INJURY>0.5,"Yes","No")
acc1.prob
```
P(Injury = YES | WEATHER_R = 1, TRAF_CON_R = 0) = Yes
P(Injury = YES | WEATHER_R = 1, TRAF_CON_R = 1) = No
P(Injury = YES | WEATHER_R = 1, TRAF_CON_R = 2) = No
P(Injury = YES | WEATHER_R = 2, TRAF_CON_R = 0) = No
P(Injury = YES | WEATHER_R = 2, TRAF_CON_R = 1) = No
P(Injury = YES | WEATHER_R = 2, TRAF_CON_R = 2) = No
P(Injury = NO | WEATHER_R = 1, TRAF_CON_R = 0) = Yes
P(Injury = NO | WEATHER_R = 1, TRAF_CON_R = 1) = No
P(Injury = NO | WEATHER_R = 1, TRAF_CON_R = 2) = No
P(Injury = NO | WEATHER_R = 2, TRAF_CON_R = 0) = Yes
P(Injury = NO | WEATHER_R = 2, TRAF_CON_R = 1) = No
P(Injury = NO | WEATHER_R = 2, TRAF_CON_R = 2) = No

iv)Naive Bayes:

```{r}
prob <- 2/3 * 0/3 * 3/12
prob
```
p(Injury=Yes|TRAF_CON_R=1, WEATHER_R=1)=0

v)
```{r}
library(e1071)
library(klaR)
library(caret)
n1<-naiveBayes(INJURY ~ ., data = x.df)
predict(n1, newdata = x.df,type = "raw")

library(caret)
o1=x.df[,-3]
o2=x.df$INJURY
cla1 <- train(o1,o2,'nb', trControl = trainControl(method = 'cv',number=10))
cla1
pred<-predict(cla1$finalModel,o1)
pred
table(pred$class,o2)

```
C)

From the following model, HOUR_I_R, ALCOHOL_I, WKDY_I_R, LGTCON_I_R,
MAN_COL_I, SPD_LIM can be included when weather conditions and location is not known.

Overall Error = (911+7275)/(7054+7275+911+1633)*100=48.51

There is no improvement in the model.

We get a probability of zero for the given conditional probability as Naive Bayes takes the probability of the category of predictor as zero.

